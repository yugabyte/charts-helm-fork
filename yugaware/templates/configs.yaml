# Copyright (c) YugaByte, Inc.
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: {{ .Release.Name }}-yugaware-global-config
  labels:
    app: {{ template "yugaware.name" . }}
    chart: {{ template "yugaware.chart" . }}
    release: {{ .Release.Name }}
    heritage: {{ .Release.Service }}
data:
  postgres_user: "postgres"
  postgres_password: "{{ b64enc (randAlphaNum 8) }}"
  postgres_db: "yugaware"
  app_secret: "{{ b64enc (randAlphaNum 64) }}"

---
apiVersion: v1
kind: ConfigMap
metadata:
  name: {{ .Release.Name }}-yugaware-app-config
  labels:
    app: {{ template "yugaware.name" . }}
    chart: {{ template "yugaware.chart" . }}
    release: {{ .Release.Name }}
    heritage: {{ .Release.Service }}
data:
  application.docker.conf: |
    play.crypto.secret=${APP_SECRET}
    play.i18n.langs = [ "en" ]
    pidfile.path = "/dev/null"
    db {
      default.url="jdbc:postgresql://127.0.0.1:5432/"${POSTGRES_DB}
      default.driver=org.postgresql.Driver
      default.username=${POSTGRES_USER}
      default.password=${POSTGRES_PASSWORD}
      default.logStatements=true
      default.migration.initOnMigrate=true
      default.migration.auto=true
    }
    ebean {
      default = ["com.yugabyte.yw.models.*"]
    }

    play.modules.enabled += "org.flywaydb.play.PlayModule"

    yb {
      devops.home = /opt/yugabyte/devops
      metrics.url = "http://127.0.0.1:9090/api/v1"
      storage.path = /opt/yugaware_data
      docker.network = bridge
      seedData = false
      swamper.targetPath = /opt/swamper_targets
      multiTenant = {{ .Values.yugaware.multiTenant }}
      releases.path = "/opt/releases"
      docker.release = "/opt/yugabyte/release"
      # TODO(bogdan): need this extra level for installing from local...
      thirdparty.packagePath = /opt/third-party/third-party
      helm.package = "{{ .Values.helm.package }}"
      helm.timeout_secs = {{ .Values.helm.timeout }}
      health.check_interval_ms = 300000
      health.status_interval_ms = 43200000
      health.default_email = "alerts@yugabyte.com"
      health.ses_email_username = "{{ .Values.yugaware.health.username }}"
      health.ses_email_password = "{{ .Values.yugaware.health.password }}"
    }
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: {{ .Release.Name }}-yugaware-nginx-config
  labels:
    app: {{ template "yugaware.name" . }}
    chart: {{ template "yugaware.chart" . }}
    release: {{ .Release.Name }}
    heritage: {{ .Release.Service }}
data:
  default.conf: |
    server {
      listen       80;
      server_name  localhost;

      proxy_http_version 1.1;
      proxy_set_header X-Real-IP  $remote_addr;
      proxy_set_header X-Forwarded-For $remote_addr;
      proxy_set_header Host $host;

      location / {
        root /yugaware-ui/public/;
        try_files $uri /index.html;
      }
      location /api {
        proxy_pass http://127.0.0.1:9000;
      }

      location ~ "^/proxy/([0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}):([0-9]{4,6})/(.*)$" {
        proxy_pass "http://$1:$2/$3$is_args$args";
        sub_filter "http://" "/proxy/";
        sub_filter "href='/" "href='/proxy/$1:$2/";
        sub_filter "href=\"/" "href=\"/proxy/$1:$2/";
        sub_filter "src='/" "src='/proxy/$1:$2/";
        sub_filter "src=\"/" "src=\"/proxy/$1:$2/";
        sub_filter_once off;
      }

      location ~ "^/proxy/(.*.svc.cluster.local):([0-9]{4,6})/(.*)$" {
        resolver 127.0.0.1:53 ipv6=off;
        proxy_pass "http://$1:$2/$3$is_args$args";
        sub_filter "http://" "/proxy/";
        sub_filter "href='/" "href='/proxy/$1:$2/";
        sub_filter "href=\"/" "href=\"/proxy/$1:$2/";
        sub_filter "src='/" "src='/proxy/$1:$2/";
        sub_filter "src=\"/" "src=\"/proxy/$1:$2/";
        sub_filter_once off;
      }
    }
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: {{ .Release.Name }}-yugaware-prometheus-config
  labels:
    app: {{ template "yugaware.name" . }}
    chart: {{ template "yugaware.chart" . }}
    release: {{ .Release.Name }}
    heritage: {{ .Release.Service }}
data:
  prometheus.yml: |
    global:
        scrape_interval:     10s
        evaluation_interval: 10s
    scrape_configs:
      - job_name: 'kubernetes-nodes'

        scheme: https

        tls_config:
          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token

        kubernetes_sd_configs:
        - role: node

        relabel_configs:
        - action: labelmap
          regex: __meta_kubernetes_node_label_(.+)
        - target_label: __address__
          replacement: kubernetes.default.svc:443
        - source_labels: [__meta_kubernetes_node_name]
          regex: (.+)
          target_label: __metrics_path__
          replacement: /api/v1/nodes/${1}/proxy/metrics
        metric_relabel_configs:
          # Save the name of the metric so we can group_by since we cannot by __name__ directly...
          - source_labels: ["__name__"]
            regex: "(.*)"
            target_label: "saved_name"
            replacement: "$1"


      - job_name: 'kubernetes-pods'

        kubernetes_sd_configs:
        - role: pod

        relabel_configs:
        - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
          action: keep
          regex: true
        - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
          action: replace
          target_label: __metrics_path__
          regex: (.+)
        - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
          action: replace
          regex: ([^:]+)(?::\d+)?;(\d+)
          replacement: $1:$2
          target_label: __address__
        - action: labelmap
          regex: __meta_kubernetes_pod_label_(.+)
        - source_labels: [__meta_kubernetes_namespace]
          action: replace
          target_label: kubernetes_namespace
        - source_labels: [__meta_kubernetes_pod_name]
          action: replace
          target_label: kubernetes_pod_name
        metric_relabel_configs:
          # Save the name of the metric so we can group_by since we cannot by __name__ directly...
          - source_labels: ["__name__"]
            regex: "(.*)"
            target_label: "saved_name"
            replacement: "$1"

      - job_name: 'kubernetes-cadvisor'

        scheme: https

        tls_config:
          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token

        kubernetes_sd_configs:
        - role: node

        relabel_configs:
        - action: labelmap
          regex: __meta_kubernetes_node_label_(.+)
        - target_label: __address__
          replacement: kubernetes.default.svc:443
        - source_labels: [__meta_kubernetes_node_name]
          regex: (.+)
          target_label: __metrics_path__
          replacement: /api/v1/nodes/${1}/proxy/metrics/cadvisor
        metric_relabel_configs:
          # Save the name of the metric so we can group_by since we cannot by __name__ directly...
          - source_labels: ["__name__"]
            regex: "(.*)"
            target_label: "saved_name"
            replacement: "$1"

      - job_name: "node"
        file_sd_configs:
          - files:
            - '/opt/swamper_targets/node.*.json'
        metric_relabel_configs:
          # Save the name of the metric so we can group_by since we cannot by __name__ directly...
          - source_labels: ["__name__"]
            regex: "(.*)"
            target_label: "saved_name"
            replacement: "$1"

      - job_name: "yugabyte"
        metrics_path: "/prometheus-metrics"
        file_sd_configs:
          - files:
            - '/opt/swamper_targets/yugabyte.*.json'
        metric_relabel_configs:
          # Save the name of the metric so we can group_by since we cannot by __name__ directly...
          - source_labels: ["__name__"]
            regex: "(.*)"
            target_label: "saved_name"
            replacement: "$1"
          # The following basically retrofit the handler_latency_* metrics to label format.
          - source_labels: ["__name__"]
            regex: "handler_latency_(yb_[^_]*)_([^_]*)_([^_]*)(.*)"
            target_label: "server_type"
            replacement: "$1"
          - source_labels: ["__name__"]
            regex: "handler_latency_(yb_[^_]*)_([^_]*)_([^_]*)(.*)"
            target_label: "service_type"
            replacement: "$2"
          - source_labels: ["__name__"]
            regex: "handler_latency_(yb_[^_]*)_([^_]*)_([^_]*)(_sum|_count)"
            target_label: "service_method"
            replacement: "$3"
          - source_labels: ["__name__"]
            regex: "handler_latency_(yb_[^_]*)_([^_]*)_([^_]*)(_sum|_count)"
            target_label: "__name__"
            replacement: "rpc_latency$4"
